{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain neo4j openai wikipedia tiktoken langchain-openai\n",
    "# from https://github.com/tomasonjo/blogs/blob/master/llm/openaifunction_constructing_graph.ipynb\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='secrets.env')\n",
    "graph = Neo4jGraph(\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    "    GraphDocument,\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.pydantic_v1 import Field, BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, name, description):\n",
    "        self.name = name\n",
    "        self.id = os.urandom(16).hex()\n",
    "        self.description = description\n",
    "    \n",
    "class Graph():\n",
    "    # store Nodes in a hashMap: id -> Node\n",
    "    # store the edges as lists in a dict: sourceId -> [(neighborId, relationship)]\n",
    "    # store the edges as dicts in a dict: sourceId -> {neighborId -> (neighborNode, relationship)}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.edgesMapToList = {}\n",
    "        self.edgesMapToMap = {}\n",
    "    \n",
    "    def add_node(self, node: Node):\n",
    "        self.nodes[node.id] = node\n",
    "        self.edgesMapToList[node.id] = []\n",
    "        self.edgesMapToMap[node.id] = {}\n",
    "\n",
    "    def add_edge(self, source: Node, target: Node, relationship: str):\n",
    "        if (self.nodes.get(source.id) == None):\n",
    "            raise Exception(\"Source node not found\")\n",
    "        elif (self.nodes.get(target.id) == None):\n",
    "            raise Exception(\"Target node not found\")\n",
    "        \n",
    "        self.edgesMapToList[source.id].append((target.id, relationship))\n",
    "        self.edgesMapToMap[source.id][target.id] = (target, relationship)\n",
    "\n",
    "    def get_neighbors(self, node: Node):\n",
    "        return self.edgesMapToList[node.id]\n",
    "    \n",
    "    def is_neighbor(self, node: Node, neighbor: Node):\n",
    "        return self.edgesMapToMap[node.id].get(neighbor.id) != None\n",
    "    \n",
    "    def get_list_nodes(self):\n",
    "        return self.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Test cases for above\n",
    "test1 = Node(\"test1\", \"test node #1\")\n",
    "test2 = Node(\"test2\", \"test node #2\")\n",
    "test3 = Node(\"test3\", \"test node #3\")\n",
    "graph = Graph()\n",
    "graph.add_node(test1)\n",
    "graph.add_node(test2)\n",
    "graph.add_node(test3)\n",
    "graph.add_edge(test1, test2, \"dislikes\")\n",
    "print(graph.is_neighbor(test1, test2));\n",
    "print(graph.is_neighbor(test2, test3));\n",
    "print(graph.is_neighbor(test2, test1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return first_word + \"\".join(capitalized_words)\n",
    "\n",
    "def props_to_dict(props) -> dict:\n",
    "    properties = {}\n",
    "    if not props:\n",
    "        return properties\n",
    "    for p in props:\n",
    "        properties[format_property_key(p.key)] = p.value\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    properties = props_to_dict(node.properties) if node.properties else {}\n",
    "    properties[\"name\"] = node.id.title()\n",
    "    return BaseNode(\n",
    "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
    "    )\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "\n",
    "def get_extraction_chain(\n",
    "        allowed_nodes: Optional[List[str]] = None,\n",
    "        allowed_rels: Optional[List[str]] = None\n",
    "    ):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\n",
    "            \"system\",\n",
    "            f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
    "    ## 1. Overview\n",
    "    You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "    - **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
    "    - The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
    "    ## 2. Labeling Nodes\n",
    "    - **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "    - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
    "    - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
    "    {'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
    "    {'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
    "    ## 3. Handling Numerical Data and Dates\n",
    "    - Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
    "    - **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "    - **Property Format**: Properties must be in a key-value format.\n",
    "    - **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "    - **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
    "    ## 4. Coreference Resolution\n",
    "    - **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
    "    If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
    "    always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
    "    Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
    "    ## 5. Strict Compliance\n",
    "    Adhere to the rules strictly. Non-compliance will result in termination.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"Use the given format to extract info from the following input: {input}\"),\n",
    "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "        ])\n",
    "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_store_graph(\n",
    "    document: Document,\n",
    "    nodes:Optional[List[str]] = None,\n",
    "    rels:Optional[List[str]]=None) -> None:\n",
    "    # Extract graph data using OpenAI functions\n",
    "    extract_chain = get_extraction_chain(nodes, rels)\n",
    "    data = extract_chain.invoke(document.page_content)['function']\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "      nodes = [map_to_base_node(node) for node in data.nodes],\n",
    "      relationships = [map_to_base_relationship(rel) for rel in data.rels],\n",
    "      source = document\n",
    "    )\n",
    "    # Store information into a graph\n",
    "    graph.add_graph_documents([graph_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Read the wikipedia article\n",
    "raw_documents = WikipediaLoader(query=\"History of France\").load()\n",
    "# Define chunking strategy\n",
    "text_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
    "\n",
    "# Only take the first the raw_documents\n",
    "documents = text_splitter.split_documents(raw_documents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    extract_and_store_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Delete the graph\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATCH (n) DETACH DELETE n\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete the graph\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenster/knowledge-graph/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (c:Country {name: \"France\"})-[:HASALLIANCE]->(a:Alliance {name: \"Axis Powers\"}) RETURN c, a\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'c': {\"hundredYears'War\": \"A succession crisis in 1328 led to the Hundred Years' War between the House of Valois and the House of Plantagenet. The war began in 1337 following Philip VI's attempt to seize the Duchy of Aquitaine from its hereditary holder, Edward III of England, the Plantagenet claimant to the French throne. Despite early Plantagenet victories, fortunes turned in favor of the Valois. A notable figure of the war was Joan of Arc, a French peasant girl who led forces against the English, establishing herself as a national heroine. The war ended with a Valois victory in 1453.\", 'frenchRevolution': \"In the late 18th century the monarchy and associated institutions were overthrown in the French Revolution. The Revolutionary Tribunal executed political opponents by guillotine, instituting the Reign of Terror (1793–94). The country was governed as a Republic, until Napoleon's French Empire was declared in 1804.\", 'colonization': 'Over the first millennium BC the Greeks, Romans and Carthaginians established colonies on the Mediterranean coast and offshore islands.', 'worldWarIi': 'France was one of the Allied Powers in World War II, but was conquered by Nazi Germany in 1940. The Third Republic was dismantled, and most of the country was controlled directly by Germany, while the south was controlled until 1942 by the collaborationist Vichy government.', 'romanRule': 'The Roman Republic annexed southern Gaul in the late 2nd century BC, and legions under Julius Caesar conquered the rest of Gaul in the Gallic Wars of 58–51 BC. A Gallo-Roman culture emerged and Gaul was increasingly integrated into the Roman Empire.', 'name': 'France', 'medievalPeriod': \"The medieval Kingdom of France emerged from the western part of Charlemagne's Carolingian Empire, known as West Francia, and achieved increasing prominence under the rule of the House of Capet, founded in 987.\", 'id': 'France', 'history': 'The first written records for the history of France appeared in the Iron Age. What is now France made up the bulk of the region known to the Romans as Gaul. Greek writers noted the presence of three main ethno-linguistic groups in the area: the Gauls, Aquitani and Belgae. The Gauls, the largest group, were Celtic people speaking Gaulish.', 'frankishRule': 'In the later stages of the Roman Empire, Gaul was subject to barbarian raids and migration, most importantly by the Germanic Franks. The Frankish king Clovis I united most of Gaul in the late 5th century, setting the stage for Frankish dominance for hundreds of years. Frankish power reached its fullest extent under Charlemagne.', 'worldWarI': 'France was one of the Triple Entente powers in World War I against Germany and the Central Powers.'}, 'a': {'name': 'Axis Powers', 'id': 'Axis Powers'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, France was not allied with the Axis Powers.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the knowledge graph in a RAG application\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
    "    validate_cypher=True, # Validate relationship directions\n",
    "    verbose=True\n",
    ")\n",
    "cypher_chain.run(\"Was France allied with the Axis powers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"]) \n",
    "def ask_gpt_if_same(node1: str, node2: str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[    \n",
    "            # System basically tells the chat gpt model how to act\n",
    "            {\"role\": \"system\", \"content\": \"You are the most intelligent comparison agent in the world. You can compare any two pieces of text and accurately tell if they refer to the same thing or not.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Do the following two nodes mean exactly the same thing? Node 1: \" + node1 + \". Node 2: \" + node2 + \". Answer yes or no.\"}\n",
    "        ]\n",
    "    ) \n",
    "    return response.choices[0].message.content.strip().lower() == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_nodes(graph):\n",
    "    query = \"MATCH (n) RETURN n\"\n",
    "    result = graph.query(query)\n",
    "    return result\n",
    "nodes = get_all_nodes(graph)\n",
    "# print(nodes[1])\n",
    "# compare each pair of nodes\n",
    "for i, node in enumerate(nodes):\n",
    "    for j, node2 in enumerate(nodes):\n",
    "        if i != j:\n",
    "            print(node)\n",
    "            if (ask_gpt_if_same(node.get('n').get('name'), node2.get('n').get('name'))):\n",
    "                print(f\"Node {i} and Node {j} mean the same thing.\")\n",
    "\n",
    "# for i, node in enumerate(nodes):\n",
    "#     print(i,node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_node_but_retain_edges(graph, node_id, new_node_id):\n",
    "    # Reassign relationships to the new node\n",
    "    query = f\"\"\"\n",
    "    MATCH (n {{id: '{node_id}'}})-[r]->(m)\n",
    "    CREATE (new {{id: '{new_node_id}'}})-[new_r:TYPE(r)]->(m)\n",
    "    SET new_r = r\n",
    "    WITH n, r\n",
    "    MATCH (m)-[r2]->(n)\n",
    "    CREATE (m)-[new_r2:TYPE(r2)]->(new {{id: '{new_node_id}'}})\n",
    "    SET new_r2 = r2\n",
    "    DELETE r, r2\n",
    "    \"\"\"\n",
    "    graph.query(query)\n",
    "    \n",
    "    # Delete the original node\n",
    "    delete_query = f\"MATCH (n {{id: '{node_id}'}}) DELETE n\"\n",
    "    graph.query(delete_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

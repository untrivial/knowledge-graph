{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv(dotenv_path='secrets.env')\n",
    "\n",
    "url=os.environ[\"NEO4J_URI\"]\n",
    "username=os.environ[\"NEO4J_USERNAME\"]\n",
    "password=os.environ[\"NEO4J_PASSWORD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the graph\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(url, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(tx, name, type):\n",
    "    tx.run(f\"CREATE (n:{type} {{name: $name}})\", name=name)\n",
    "\n",
    "def add_edge(tx, source, target, type):\n",
    "    tx.run(f\"MATCH (s), (t) WHERE s.name = $source AND t.name = $target CREATE (s)-[r:{type}]->(t)\", source=source, target=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session() as session:\n",
    "#     session.execute_write(add_node, \"The Pentagon\", \"Building\")\n",
    "#     session.execute_write(add_edge, \"Alice\", \"The Pentagon\", \"LIVES_IN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_functions = [\n",
    "    {\n",
    "        # could add Properties to the node\n",
    "        \"name\": 'extract_node',\n",
    "        \"description\": \"Extract a node entity from a document\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A short name for the node entity.\"\n",
    "                },\n",
    "                \"type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of the node entity.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\", \"type\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_functions = [\n",
    "    {\n",
    "        \"name\": \"extract_relationship\",\n",
    "        \"description\": \"Extract a relationship between two nodesfrom a document\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"source\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the source node.\"\n",
    "                },\n",
    "                \"target\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the target node.\"\n",
    "                },\n",
    "                \"type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of the relationship.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"source\", \"target\", \"type\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"Alice lives in the Pentagon. Bob lives in the White House. Joe is Alice's brother. Bob enjoys reading French History books with Joe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PARAMETERS '''\n",
    "\n",
    "# Max number of times the identification loops will run\n",
    "loop_parameter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify nodes in a block of text\n",
    "\n",
    "def get_nodes_from_text(text, loop_parameter=loop_parameter):\n",
    "    nodes = []\n",
    "    for i in range(loop_parameter):\n",
    "        decide_continue_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to answer a yes or no question: whether you have found all nodes (entities and concepts) in the provided text.'},\n",
    "                {'role': 'user', 'content': \n",
    "                    'The block of text is:\\n\\n' \n",
    "                    + text \n",
    "                    + '\\n\\nYou have already identified these nodes:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes) \n",
    "                    + '\\n\\nIf you think you have identified every node, please respond with the word \"yes\". Else, please respond with the word \"no\". Do not respond with anything else. You must respond with either yes or no.'}\n",
    "                ]\n",
    "        )\n",
    "        if (decide_continue_response.choices[0].message.content.lower() == 'yes'):\n",
    "            break\n",
    "        elif (decide_continue_response.choices[0].message.content.lower() == 'no'):\n",
    "            node_response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{'role': 'user', 'content': \n",
    "                        'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to identify nodes (entities and concepts) in the text. Nodes must have short, unique names and a clear type. You have already identified the following nodes\\n' + ','.join(str(x) for x in nodes) + '\\n Do not duplicate any of the nodes that you have already identified. There is a heavy penalty if you repeat the same node. If you have identified every node in the text, do not call the function.\\n\\nThe block of text is as follows: \\n\\n' + text}],\n",
    "                functions = node_functions,\n",
    "                function_call = 'auto'\n",
    "            )\n",
    "\n",
    "            if node_response.choices[0].message.function_call and node_response.choices[0].message.function_call.arguments:\n",
    "                try:\n",
    "                    json_response = json.loads(node_response.choices[0].message.function_call.arguments)\n",
    "                    if json_response not in nodes and json_response is not None:\n",
    "                        nodes.append(json_response)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSONDecodeError: {e}\")\n",
    "                    print(f\"Response content: {node_response.choices[0].message.function_call.arguments}\")\n",
    "                    continue\n",
    "            \n",
    "        else:\n",
    "            print(\"Error: Unexpected response from the model.\\n\\n\" + decide_continue_response.choices[0].message.content)\n",
    "            print(\"Nodes identified so far:\")\n",
    "            return nodes\n",
    "    \n",
    "    print(\"Finished identifying nodes.\")\n",
    "    \n",
    "    if (len(nodes) == 0):\n",
    "        print(\"Error: No nodes were identified in the text.\")\n",
    "        print(\"Trying again...\")\n",
    "        return get_nodes_from_text(text, loop_parameter)\n",
    "    else:\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = get_nodes_from_text(test_string)\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decide_continue_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to answer a yes or no question: whether you have found all nodes (entities and concepts) in the provided text.'},\n",
    "                {'role': 'user', 'content': 'hello'}\n",
    "                ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify relationships in a block of text\n",
    "\n",
    "def get_relationships_from_text(text, nodes, loop_parameter=loop_parameter):\n",
    "    relationships = []\n",
    "    node_names = [node['name'] for node in nodes]\n",
    "    for i in range(loop_parameter):\n",
    "        decide_continue_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a highly intelligent agent creating a knowledge graph from a given block of text. You have already identified all the nodes. Your job is to answer a yes or no question: whether you have found all relationships between nodes in the provided text.'},\n",
    "                {'role': 'user', 'content': \n",
    "                    'The block of text is:\\n\\n' \n",
    "                    + text \n",
    "                    + '\\n\\nYou have already identified these relationships:\\n\\n'\n",
    "                    + ','.join(str(x) for x in relationships) \n",
    "                    + '\\n\\nThis is the list of all nodes in the text:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes)\n",
    "                    + '\\n\\nIf you think you have identified every relationship, please respond with the word \"yes\". Else, please respond with the word \"no\". Do not respond with anything else. You must respond with either yes or no.'}\n",
    "                ]\n",
    "        )\n",
    "        if (decide_continue_response.choices[0].message.content.lower() == 'yes'):\n",
    "            break\n",
    "        elif (decide_continue_response.choices[0].message.content.lower() == 'no'):\n",
    "            relationship_response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{'role': 'user', 'content': \n",
    "                        'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to identify relationships between nodes (entities and concepts) in the text. Relationships must have short, unique names and a clear type. You have already identified the following relationships\\n' + ','.join(str(x) for x in relationships) + '\\n Do not duplicate any of the relationships that you have already identified. There is a heavy penalty if you repeat the same relationship.' + '\\n\\nThis is the provided list of all nodes in the text:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes) + '\\n\\n The source and target nodes in any relationship must be in the provided list of nodes. You must use nodes from the provided list of nodes. Do not create new nodes that are not in the list. If you have identified every relationship in the text, do not call the function.\\n\\nThe block of text is as follows: \\n\\n' + text}],\n",
    "                functions = relationship_functions,\n",
    "                function_call = 'auto'\n",
    "            )\n",
    "            \n",
    "            if relationship_response.choices[0].message.function_call and relationship_response.choices[0].message.function_call.arguments:\n",
    "                try:\n",
    "                    json_response = json.loads(relationship_response.choices[0].message.function_call.arguments)\n",
    "                    if json_response not in relationships and json_response is not None:\n",
    "                        if json_response['source'] in node_names and json_response['target'] in node_names:\n",
    "                            relationships.append(json_response)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSONDecodeError: {e}\")\n",
    "                    print(f\"Response content: {relationship_response.choices[0].message.function_call.arguments}\")\n",
    "                    continue\n",
    "        else:\n",
    "            print(\"Error: Unexpected response from the model.\\n\\n\" + decide_continue_response.choices[0].message.content)\n",
    "            print(\"Relationships identified so far:\")\n",
    "            return relationships\n",
    "    \n",
    "    print(\"Finished identifying relationships.\")\n",
    "    \n",
    "    if (len(relationships) == 0):\n",
    "        print(\"Error: No relationships were identified in the text.\")\n",
    "        print(\"Trying again...\")\n",
    "        return get_relationships_from_text(text, nodes, loop_parameter)\n",
    "    else:\n",
    "        return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = get_relationships_from_text(test_string, nodes, loop_parameter=loop_parameter)\n",
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=300, chunk_overlap=0, strip_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import WikipediaLoader\n",
    "# raw_documents = WikipediaLoader(query=\"History of France\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi, urllib.parse\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent = 'ContentSummary (axchenster@gmail.com)',\n",
    "    language = 'en',\n",
    "    extract_format = wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_name(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    # Extract the path component and then split it by '/'\n",
    "    path_segments = parsed_url.path.split('/')\n",
    "    # The article name is typically the last segment of the path, decode it from URL format to plain text\n",
    "    article_name = urllib.parse.unquote(path_segments[-1])\n",
    "    return article_name\n",
    "\n",
    "def fetch_content_from_url(url):\n",
    "    # Code to fetch content from URL\n",
    "    return wiki.page(extract_article_name(url)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = text_splitter.split_text(fetch_content_from_url('https://en.wikipedia.org/wiki/History_of_France'))\n",
    "documents = text_splitter.split_text(fetch_content_from_url('https://en.wikipedia.org/wiki/American_Airlines'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./texts/moon_speech.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_nodes_rels(document):\n",
    "    with driver.session() as session:\n",
    "        nodes = get_nodes_from_text(document)\n",
    "        relationships = get_relationships_from_text(document, nodes)\n",
    "        for node in nodes:\n",
    "            try:\n",
    "                session.execute_write(add_node, node['name'], node['type'])\n",
    "                print('Uploaded node: ' + node['name'] + '; ' + node['type'])\n",
    "            except Exception as e:\n",
    "                print('Error uploading node: ' + node['name'] + ';\\n ' + node['type'] + ';\\n ' + str(e))\n",
    "        for relationship in relationships:\n",
    "            try:\n",
    "                session.execute_write(add_edge, relationship['source'], relationship['target'], relationship['type'])\n",
    "                print('Uploaded relationship: ' + relationship['source'] + '; ' + relationship['target'] + '; ' + relationship['type'])\n",
    "            except Exception as e:\n",
    "                print('Error uploading relationship: ' + relationship['source'] + '; ' + relationship['target'] + '; ' + relationship['type'] + ';\\n ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    upload_nodes_rels(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    for i in range(len(documents)):\n",
    "        nodes = get_nodes_from_text(documents[i])\n",
    "        relationships = get_relationships_from_text(documents[i], nodes)\n",
    "        for node in nodes:\n",
    "            session.execute_write(add_node, node)\n",
    "        session.execute_write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.execute_write(add_node, \"The Pentagon\", \"Building\")\n",
    "    session.execute_write(add_edge, \"Alice\", \"The Pentagon\", \"LIVES_IN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

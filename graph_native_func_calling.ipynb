{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv(dotenv_path='secrets.env')\n",
    "\n",
    "url=os.environ[\"NEO4J_URI\"]\n",
    "username=os.environ[\"NEO4J_USERNAME\"]\n",
    "password=os.environ[\"NEO4J_PASSWORD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the graph\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(url, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node(tx, name, type):\n",
    "    tx.run(f\"CREATE (n:{type} {{name: $name}})\", name=name)\n",
    "\n",
    "def add_edge(tx, source, target, type):\n",
    "    tx.run(f\"MATCH (s), (t) WHERE s.name = $source AND t.name = $target CREATE (s)-[r:{type}]->(t)\", source=source, target=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session() as session:\n",
    "#     session.execute_write(add_node, \"The Pentagon\", \"Building\")\n",
    "#     session.execute_write(add_edge, \"Alice\", \"The Pentagon\", \"LIVES_IN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_functions = [\n",
    "    {\n",
    "        # could add Properties to the node\n",
    "        \"name\": 'extract_node',\n",
    "        \"description\": \"Extract a node entity from a document\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A short name for the node entity.\"\n",
    "                },\n",
    "                \"type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of the node entity.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\", \"type\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_functions = [\n",
    "    {\n",
    "        \"name\": \"extract_relationship\",\n",
    "        \"description\": \"Extract a relationship between two nodesfrom a document\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"source\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the source node.\"\n",
    "                },\n",
    "                \"target\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the target node.\"\n",
    "                },\n",
    "                \"type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of the relationship.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"source\", \"target\", \"type\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"Alice lives in the Pentagon. Bob lives in the White House. Joe is Alice's brother. Bob enjoys reading French History books with Joe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PARAMETERS '''\n",
    "\n",
    "loop_parameter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify nodes in a block of text\n",
    "\n",
    "def get_nodes_from_text(text, loop_parameter=loop_parameter):\n",
    "    nodes = []\n",
    "    for i in range(loop_parameter):\n",
    "        decide_continue_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to answer a yes or no question: whether you have found all nodes (entities and concepts) in the provided text.'},\n",
    "                {'role': 'user', 'content': \n",
    "                    'The block of text is:\\n\\n' \n",
    "                    + text \n",
    "                    + '\\n\\nYou have already identified these nodes:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes) \n",
    "                    + '\\n\\nIf you think you have identified every node, please respond with the word \"yes\". Else, please respond with the word \"no\". Do not respond with anything else. You must respond with either yes or no.'}\n",
    "                ]\n",
    "        )\n",
    "        if (decide_continue_response.choices[0].message.content.lower() == 'yes'):\n",
    "            break\n",
    "        elif (decide_continue_response.choices[0].message.content.lower() == 'no'):\n",
    "            node_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{'role': 'user', 'content': \n",
    "                        'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to identify nodes (entities and concepts) in the text. Nodes must have short, unique names and a clear type. You have already identified the following nodes\\n' + ','.join(str(x) for x in nodes) + '\\n Do not duplicate any of the nodes that you have already identified. There is a heavy penalty if you repeat the same node. If you have identified every node in the text, do not call the function.\\n\\nThe block of text is as follows: \\n\\n' + text}],\n",
    "                functions = node_functions,\n",
    "                function_call = 'auto'\n",
    "            )\n",
    "\n",
    "            if (node_response.choices[0].message.function_call and node_response.choices[0].message.function_call.arguments):\n",
    "                json_response = json.loads(node_response.choices[0].message.function_call.arguments)\n",
    "                if (json_response not in nodes and json_response is not None):\n",
    "                    nodes.append(json_response)\n",
    "        else:\n",
    "            print(\"Error: Unexpected response from the model.\\n\\n\" + decide_continue_response.choices[0].message.content)\n",
    "            print(\"Nodes identified so far:\")\n",
    "            return nodes\n",
    "    \n",
    "    print(\"Finished identifying nodes.\")\n",
    "    \n",
    "    if (len(nodes) == 0):\n",
    "        print(\"Error: No nodes were identified in the text.\")\n",
    "        print(\"Trying again...\")\n",
    "        return get_nodes_from_text(text, loop_parameter)\n",
    "    else:\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished identifying nodes.\n",
      "{'name': 'Alice', 'type': 'Person'}\n",
      "{'name': 'the Pentagon', 'type': 'Place'}\n",
      "{'name': 'White House', 'type': 'Place'}\n",
      "{'name': 'Bob', 'type': 'Person'}\n",
      "{'name': 'Joe', 'type': 'Person'}\n",
      "{'name': 'French History books', 'type': 'Concept'}\n"
     ]
    }
   ],
   "source": [
    "nodes = get_nodes_from_text(test_string)\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify relationships in a block of text\n",
    "\n",
    "def get_relationships_from_text(text, nodes, loop_parameter=loop_parameter):\n",
    "    relationships = []\n",
    "    for i in range(loop_parameter):\n",
    "        decide_continue_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a highly intelligent agent creating a knowledge graph from a given block of text. You have already identified all the nodes. Your job is to answer a yes or no question: whether you have found all relationships between nodes in the provided text.'},\n",
    "                {'role': 'user', 'content': \n",
    "                    'The block of text is:\\n\\n' \n",
    "                    + text \n",
    "                    + '\\n\\nYou have already identified these relationships:\\n\\n'\n",
    "                    + ','.join(str(x) for x in relationships) \n",
    "                    + '\\n\\nThis is the list of all nodes in the text:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes)\n",
    "                    + '\\n\\nIf you think you have identified every relationship, please respond with the word \"yes\". Else, please respond with the word \"no\". Do not respond with anything else. You must respond with either yes or no.'}\n",
    "                ]\n",
    "        )\n",
    "        if (decide_continue_response.choices[0].message.content.lower() == 'yes'):\n",
    "            break\n",
    "        elif (decide_continue_response.choices[0].message.content.lower() == 'no'):\n",
    "            relationship_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{'role': 'user', 'content': \n",
    "                        'You are a highly intelligent agent creating a knowledge graph from a given block of text. Your job is to identify relationships between nodes (entities and concepts) in the text. Relationships must have short, unique names and a clear type. You have already identified the following relationships\\n' + ','.join(str(x) for x in relationships) + '\\n Do not duplicate any of the relationships that you have already identified. There is a heavy penalty if you repeat the same relationship.' + '\\n\\nThis is the list of all nodes in the text:\\n\\n'\n",
    "                    + ','.join(str(x) for x in nodes) + '\\n\\nIf you have identified every relationship in the text, do not call the function.\\n\\nThe block of text is as follows: \\n\\n' + text}],\n",
    "                functions = relationship_functions,\n",
    "                function_call = 'auto'\n",
    "            )\n",
    "        \n",
    "            if (relationship_response.choices[0].message.function_call and relationship_response.choices[0].message.function_call.arguments):\n",
    "                json_response = json.loads(relationship_response.choices[0].message.function_call.arguments)\n",
    "                if (json_response not in relationships and json_response is not None):\n",
    "                    relationships.append(json_response) \n",
    "        else:\n",
    "            print(\"Error: Unexpected response from the model.\\n\\n\" + decide_continue_response.choices[0].message.content)\n",
    "            print(\"Relationships identified so far:\")\n",
    "            return relationships\n",
    "    \n",
    "    print(\"Finished identifying relationships.\")\n",
    "    \n",
    "    if (len(relationships) == 0):\n",
    "        print(\"Error: No relationships were identified in the text.\")\n",
    "        print(\"Trying again...\")\n",
    "        return get_relationships_from_text(text, nodes, loop_parameter)\n",
    "    else:\n",
    "        return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished identifying relationships.\n",
      "{'source': 'Alice', 'target': 'the Pentagon', 'type': 'residence'}\n",
      "{'source': 'Bob', 'target': 'White House', 'type': 'residence'}\n",
      "{'source': 'Joe', 'target': 'Alice', 'type': 'sibling'}\n",
      "{'source': 'Bob', 'target': 'French History books', 'type': 'interest'}\n",
      "{'source': 'Bob', 'target': 'Joe', 'type': 'interest'}\n"
     ]
    }
   ],
   "source": [
    "rels = get_relationships_from_text(test_string, nodes, loop_parameter=loop_parameter)\n",
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=200, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"moon_speech.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Pitzer, Mr. Vice President, Governor, Congressman Thomas, Senator Wiley, and Congressman Miller, Mr. Webb, Mr. Bell, scientists, distinguished guests, and ladies and gentlemen:\n",
      "\n",
      "I appreciate your president having made me an honorary visiting professor, and I will assure you that my first lecture will be very brief.\n",
      "\n",
      "I am delighted to be here, and I’m particularly delighted to be here on this occasion.\n",
      "\n",
      "We meet at a college noted for knowledge, in a city noted for progress, in a state noted for strength, and we stand in need of all three, for we meet in an hour of change and challenge, in a decade of hope and fear, in an age of both knowledge and ignorance. The greater our knowledge increases, the greater our ignorance unfolds.\n",
      "\n",
      "Despite the striking fact that most of the scientists that the world has ever known are alive and working today, despite the fact that this nation’s own scientific manpower is\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished identifying nodes.\n",
      "Finished identifying relationships.\n",
      "President Pitzer; Person\n",
      "Mr. Vice President; Person\n",
      "Governor; Person\n",
      "Congressman Thomas; Person\n",
      "Senator Wiley; Person\n",
      "Congressman Miller; Person\n",
      "Mr. Webb; Person\n",
      "Mr. Bell; Person\n",
      "scientists; Group\n",
      "distinguished guests; Group\n",
      "College; knowledge; noted_for\n",
      "President Pitzer; honorary visiting professor; appointed_as\n",
      "College; progress; noted_for\n",
      "College; strength; noted_for\n",
      "scientists; world; exists_in\n",
      "College; city; located_in\n",
      "President Pitzer; Mr. Vice President; addressed\n",
      "Finished identifying nodes.\n",
      "Finished identifying relationships.\n",
      "12 years; time period\n",
      "rate of growth; concept\n",
      "unknown; concept\n",
      "human history; concept\n",
      "50,000 years; time period\n",
      "three times; comparative measurement\n",
      "time span of a half-century; time period\n",
      "10 years ago; time period\n",
      "12 years; rate of growth; duration\n",
      "rate of growth; three times; comparison\n",
      "50,000 years; time span of a half-century; condensed representation\n",
      "vast stretches of the unknown; collective comprehension; comparison\n",
      "50,000 years; human history; representation\n",
      "advanced man; 40 years; progress milestone\n",
      "10 years ago; man emerged from caves; event\n",
      "writing and cart usage; five years ago; technological milestone\n",
      "less than two months ago; 50-year span of human history; recent event\n",
      "12 years; doubling; time frame\n",
      "Finished identifying nodes.\n",
      "Finished identifying relationships.\n",
      "steam engine; Invention\n",
      "gravity; Concept\n",
      "electric lights; Invention\n",
      "telephones; Invention\n",
      "automobiles; Invention\n",
      "airplanes; Invention\n",
      "penicillin; Invention\n",
      "television; Invention\n",
      "nuclear power; Invention\n",
      "spacecraft; Invention\n",
      "steam engine; source of power; provided\n",
      "Newton; gravity; explored\n",
      "electric lights; available; became\n",
      "telephones; available; became\n",
      "automobiles; available; became\n",
      "airplanes; available; became\n",
      "penicillin; develop; was\n",
      "spacecraft; Venus; reach\n",
      "television; develop; was\n",
      "nuclear power; develop; was\n",
      "Finished identifying nodes.\n",
      "Finished identifying relationships.\n",
      "William Bradford; Person\n",
      "Plymouth Bay Colony; Place\n",
      "exploration of space; Event\n",
      "quest for knowledge and progress; Concept\n",
      "industrial revolutions; Event\n",
      "founding of the Plymouth Bay Colony; Event\n",
      "modern invention; Event\n",
      "nuclear power; Event\n",
      "William Bradford; founding of the Plymouth Bay Colony; spoke_about\n",
      "William Bradford; Plymouth Bay Colony; spoke_about\n",
      "industrial revolutions; modern invention; preceded\n",
      "quest for knowledge and progress; exploration of space; drive\n",
      "industrial revolutions; nuclear power; preceded\n",
      "William Bradford; great and honorable actions; spoke_about\n",
      "Finished identifying nodes.\n",
      "Finished identifying relationships.\n",
      "space; place\n",
      "moon; celestial_body\n",
      "planets; celestial_body\n",
      "world; place\n",
      "conquest; concept\n",
      "freedom; concept\n",
      "peace; concept\n",
      "nation; entity\n",
      "weapons of mass destruction; concept\n",
      "knowledge; concept\n",
      "world; space; look into\n",
      "world; moon; look into\n",
      "space; planets; includes\n",
      "space; moon; includes\n",
      "nation; space; vow not to see filled by\n",
      "space; conquest; not governed by\n",
      "world; freedom; look into\n",
      "space; peace; governed by\n",
      "freedom; space; govern\n",
      "space; weapons of mass destruction; not filled with\n",
      "Finished identifying nodes.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents)):\n\u001b[1;32m      2\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m get_nodes_from_text(documents[i])\n\u001b[0;32m----> 3\u001b[0m     relationships \u001b[38;5;241m=\u001b[39m \u001b[43mget_relationships_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[74], line 33\u001b[0m, in \u001b[0;36mget_relationships_from_text\u001b[0;34m(text, nodes, loop_parameter)\u001b[0m\n\u001b[1;32m     23\u001b[0m relationship_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     24\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     function_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (relationship_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mfunction_call \u001b[38;5;129;01mand\u001b[39;00m relationship_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mfunction_call\u001b[38;5;241m.\u001b[39marguments):\n\u001b[0;32m---> 33\u001b[0m     json_response \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelationship_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (json_response \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m relationships \u001b[38;5;129;01mand\u001b[39;00m json_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     35\u001b[0m         relationships\u001b[38;5;241m.\u001b[39mappend(json_response) \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "for i in range(len(documents)):\n",
    "    nodes = get_nodes_from_text(documents[i])\n",
    "    relationships = get_relationships_from_text(documents[i], nodes)\n",
    "    for node in nodes:\n",
    "        print(node['name']+ '; ' + node['type'])\n",
    "    for relationship in relationships:\n",
    "        print(relationship['source'] + '; ' + relationship['target'] + '; ' + relationship['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    for i in range(len(documents)):\n",
    "        nodes = get_nodes_from_text(documents[i])\n",
    "        relationships = get_relationships_from_text(documents[i], nodes)\n",
    "        for node in nodes:\n",
    "            session.execute_write(add_node, node)\n",
    "        session.execute_write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.execute_write(add_node, \"The Pentagon\", \"Building\")\n",
    "    session.execute_write(add_edge, \"Alice\", \"The Pentagon\", \"LIVES_IN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
